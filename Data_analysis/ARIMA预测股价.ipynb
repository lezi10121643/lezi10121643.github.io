{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'TimeSeries'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4bf20dcbaffc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpylab\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpylab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstyle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marima_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mARIMA\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraphics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsaplots\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_acf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_pacf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\arima_model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m from statsmodels.tools.decorators import (cache_readonly,\n\u001b[0;32m     21\u001b[0m                                           resettable_cache)\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsa_model\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtsbase\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapper\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregression\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0myule_walker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGLS\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapper\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetools\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhandle_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrecipr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnan_dot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrast\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mContrastResults\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnp_matrix_rank\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTimeSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m from statsmodels.tools.decorators import (resettable_cache, cache_readonly,\n\u001b[0;32m     10\u001b[0m                                           cache_writable)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'TimeSeries'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "    作者:     梁斌\n",
    "    版本:     1.0\n",
    "    日期:     2017/02/18\n",
    "    项目名称： 股票数据分析\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import pandas_datareader\n",
    "import datetime\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pylab import style\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "style.use('ggplot')     # 设置图片显示的主题样式\n",
    "\n",
    "# 解决matplotlib显示中文问题\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 指定默认字体\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 解决保存图像是负号'-'显示为方块的问题\n",
    "\n",
    "\n",
    "def run_main():\n",
    "    \"\"\"\n",
    "        主函数\n",
    "    \"\"\"\n",
    "    # 1. 准备数据\n",
    "    # 指定股票分析开始日期\n",
    "    start_date = datetime.datetime(2007, 1, 1)\n",
    "    # 指定股票分析截止日期\n",
    "    end_date = datetime.datetime(2017, 3, 1)\n",
    "    # 股票代码\n",
    "    stock_code = '600519.SS'    # 沪市贵州茅台\n",
    "\n",
    "    stock_df = pandas_datareader.data.DataReader(\n",
    "                        stock_code, 'yahoo', start_date, end_date\n",
    "                )\n",
    "    # 预览数据\n",
    "    print(stock_df.head())\n",
    "\n",
    "    # 2. 可视化数据\n",
    "    plt.plot(stock_df['Close'])\n",
    "    plt.title('股票每日收盘价')\n",
    "    plt.show()\n",
    "\n",
    "    # 按周重采样\n",
    "    stock_s = stock_df['Close'].resample('W-MON').mean()\n",
    "    stock_train = stock_s['2014':'2016']\n",
    "    plt.plot(stock_train)\n",
    "    plt.title('股票周收盘价均值')\n",
    "    plt.show()\n",
    "\n",
    "    # 分析 ACF\n",
    "    acf = plot_acf(stock_train, lags=20)\n",
    "    plt.title(\"股票指数的 ACF\")\n",
    "    acf.show()\n",
    "\n",
    "    # 分析 PACF\n",
    "    pacf = plot_pacf(stock_train, lags=20)\n",
    "    plt.title(\"股票指数的 PACF\")\n",
    "    pacf.show()\n",
    "\n",
    "    # 3. 处理数据，平稳化数据\n",
    "    # 这里只是简单第做了一节差分，还有其他平稳化时间序列的方法\n",
    "    # 可以查询资料后改进这里的平稳化效果\n",
    "    stock_diff = stock_train.diff()\n",
    "    diff = stock_diff.dropna()\n",
    "    print(diff.head())\n",
    "    print(diff.dtypes)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(diff)\n",
    "    plt.title('一阶差分')\n",
    "    plt.show()\n",
    "\n",
    "    acf_diff = plot_acf(diff, lags=20)\n",
    "    plt.title(\"一阶差分的 ACF\")\n",
    "    acf_diff.show()\n",
    "\n",
    "    pacf_diff = plot_pacf(diff, lags=20)\n",
    "    plt.title(\"一阶差分的 PACF\")\n",
    "    pacf_diff.show()\n",
    "\n",
    "    # 4. 根据ACF和PACF定阶并建立模型\n",
    "    model = ARIMA(stock_train, order=(1, 1, 1), freq='W-MON')\n",
    "    # 拟合模型\n",
    "    arima_result = model.fit()\n",
    "    print(arima_result.summary())\n",
    "\n",
    "    # 5. 预测\n",
    "    pred_vals = arima_result.predict('20170102', '20170301',\n",
    "                                     dynamic=True, typ='levels')\n",
    "    print(pred_vals)\n",
    "\n",
    "    # 6. 可视化预测结果\n",
    "    stock_forcast = pd.concat([stock_s, pred_vals], axis=1, keys=['original', 'predicted'])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(stock_forcast)\n",
    "    plt.title('真实值vs预测值')\n",
    "    plt.savefig('./stock_pred.png', format='png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `ARIMA` not found.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'TimeSeries'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-4b3bc6774df6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpylab\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpylab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstyle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marima_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mARIMA\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraphics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsaplots\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_acf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraphics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsaplots\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_pacf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\arima_model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m from statsmodels.tools.decorators import (cache_readonly,\n\u001b[0;32m     21\u001b[0m                                           resettable_cache)\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsa_model\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtsbase\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapper\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregression\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0myule_walker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGLS\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapper\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetools\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhandle_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrecipr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnan_dot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrast\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mContrastResults\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnp_matrix_rank\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTimeSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m from statsmodels.tools.decorators import (resettable_cache, cache_readonly,\n\u001b[0;32m     10\u001b[0m                                           cache_writable)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'TimeSeries'"
     ]
    }
   ],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "\"\"\" 作者  ：  赵航\n",
    "    时间  ：  2017/04/13\n",
    "    项目名称 ： 股票预测分析\n",
    "    \"\"\"\n",
    " \n",
    " \n",
    "import pandas as pd\n",
    "import pandas_datareader\n",
    "import datetime\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pylab import style\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    " \n",
    " \n",
    "style.use('ggplot') #设置图片显示的主题样式\n",
    "#解决Matplotlib显示中文的问题\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']#指定默认字体\n",
    "plt.rcParams['axes.unicode_minus'] = False #解决保存图像是负号‘-’显示为方块的问题\n",
    " \n",
    "def run_main():\n",
    "    \"\"\"主函数\n",
    "    \"\"\"\n",
    "    #1.准备数据\n",
    "    #指定股票分析开始日期\n",
    "    start_date = datetime.datetime(2007,1,1)\n",
    "    #指定股票分析截止日期\n",
    "    end_date = datetime.datetime(2017,3,1)\n",
    "    #指定股票代码\n",
    "    stock_code = '600519.ss'\n",
    "    #调用数据包\n",
    "    stock_df = pandas_datareader.data.DataReader(stock_code,'yahoo',start_date,end_date)\n",
    "    #预览数据\n",
    "    print(stock_df.head())\n",
    " \n",
    "    #2.数据可视化\n",
    "    plt.plot(stock_df['Close'])\n",
    "    plt.title('股票每日收盘价')\n",
    "    plt.show()\n",
    "    #按周重采样\n",
    "    stock_s = stock_df['Close'].resample('W-MON').mean()#resample表示指定重采样的频率\n",
    "    stock_train = stock_s['2014':'2016']#指定训练数据，这三年的数据作为训练数据\n",
    "    plt.plot(stock_train)\n",
    "    plt.title('股票周收盘价均值')\n",
    "    plt.show()\n",
    "    #分析ACF\n",
    "    acf = plot_acf(stock_train,lags=20)\n",
    "    plt.title(\"股票指数的ACF\")\n",
    "    plt.show()\n",
    "    #分析PCAF\n",
    "    pacf = plot_pacf(stock_train,lags=20)\n",
    "    plt.title('股票指数的PACF')\n",
    "    plt.show()\n",
    "    #3.处理数据，平稳化数据\n",
    "    stock_diff = stock_train.diff()\n",
    "    diff = stock_diff.dropna()\n",
    "    print(diff.head)\n",
    "    print(diff.dtypes)\n",
    " \n",
    "    plt.figure()\n",
    "    plt.plot(diff)\n",
    "    plt.title('一阶差分')\n",
    "    plt.show()\n",
    " \n",
    "    acf_diff = plot_acf(diff,lags=20)\n",
    "    plt.title('一阶差分的ACF')\n",
    "    acf_diff.show()\n",
    " \n",
    "    pacf_diff = plot_pacf(diff,lags=20)\n",
    "    plt.title('一阶差分的PACF')\n",
    "    pacf_diff.show()\n",
    " \n",
    "    #4.根据ACF和PACF定阶并建立模型\n",
    "    model = ARIMA(stock_train,order=(1,1,1),freq='W-MON')\n",
    "    #拟合模型\n",
    "    arima_result = model.fit()\n",
    "    print(arima_result.summary)\n",
    " \n",
    "    #5.预测\n",
    "    pred_vals = arima_result.predict('20170102','20170301',\n",
    "                                     dynamic=True,typ='levels')\n",
    "    print(pred_vals)\n",
    "    #6.可视化预测结果\n",
    "    stock_forcast = pd.concat([stock_s,pred_vals],axis=1,keys=['original','predicted'])\n",
    "    plt.figure()\n",
    "    plt.plot(stock_forcast)\n",
    "    plt.title('真实值VS预测值')\n",
    "    plt.savefig('./stock_pred.png',format='png')\n",
    "    plt.show()\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    run_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Base tools for handling various kinds of data structures, attaching metadata to\n",
    "results, and doing data cleaning\n",
    "\"\"\"\n",
    "from statsmodels.compat.python import reduce, iteritems, lmap, zip, range\n",
    "from statsmodels.compat.numpy import np_matrix_rank\n",
    "import numpy as np\n",
    "from pandas import DataFrame, Series, TimeSeries, isnull\n",
    "from statsmodels.tools.decorators import (resettable_cache, cache_readonly,\n",
    "                                          cache_writable)\n",
    "import statsmodels.tools.data as data_util\n",
    "from statsmodels.tools.sm_exceptions import MissingDataError\n",
    "\n",
    "\n",
    "def _asarray_2dcolumns(x):\n",
    "    if np.asarray(x).ndim > 1 and np.asarray(x).squeeze().ndim == 1:\n",
    "        return\n",
    "\n",
    "\n",
    "def _asarray_2d_null_rows(x):\n",
    "    \"\"\"\n",
    "    Makes sure input is an array and is 2d. Makes sure output is 2d. True\n",
    "    indicates a null in the rows of 2d x.\n",
    "    \"\"\"\n",
    "    #Have to have the asarrays because isnull doesn't account for array-like\n",
    "    #input\n",
    "    x = np.asarray(x)\n",
    "    if x.ndim == 1:\n",
    "        x = x[:, None]\n",
    "    return np.any(isnull(x), axis=1)[:, None]\n",
    "\n",
    "\n",
    "def _nan_rows(*arrs):\n",
    "    \"\"\"\n",
    "    Returns a boolean array which is True where any of the rows in any\n",
    "    of the _2d_ arrays in arrs are NaNs. Inputs can be any mixture of Series,\n",
    "    DataFrames or array-like.\n",
    "    \"\"\"\n",
    "    if len(arrs) == 1:\n",
    "        arrs += ([[False]],)\n",
    "\n",
    "    def _nan_row_maybe_two_inputs(x, y):\n",
    "        # check for dtype bc dataframe has dtypes\n",
    "        x_is_boolean_array = hasattr(x, 'dtype') and x.dtype == bool and x\n",
    "        return np.logical_or(_asarray_2d_null_rows(x),\n",
    "                             (x_is_boolean_array | _asarray_2d_null_rows(y)))\n",
    "    return reduce(_nan_row_maybe_two_inputs, arrs).squeeze()\n",
    "\n",
    "\n",
    "class ModelData(object):\n",
    "    \"\"\"\n",
    "    Class responsible for handling input data and extracting metadata into the\n",
    "    appropriate form\n",
    "    \"\"\"\n",
    "    _param_names = None\n",
    "\n",
    "    def __init__(self, endog, exog=None, missing='none', hasconst=None,\n",
    "                 **kwargs):\n",
    "        if missing != 'none':\n",
    "            arrays, nan_idx = self.handle_missing(endog, exog, missing,\n",
    "                                                  **kwargs)\n",
    "            self.missing_row_idx = nan_idx\n",
    "            self.__dict__.update(arrays)  # attach all the data arrays\n",
    "            self.orig_endog = self.endog\n",
    "            self.orig_exog = self.exog\n",
    "            self.endog, self.exog = self._convert_endog_exog(self.endog,\n",
    "                                                             self.exog)\n",
    "        else:\n",
    "            self.__dict__.update(kwargs)  # attach the extra arrays anyway\n",
    "            self.orig_endog = endog\n",
    "            self.orig_exog = exog\n",
    "            self.endog, self.exog = self._convert_endog_exog(endog, exog)\n",
    "\n",
    "        # this has side-effects, attaches k_constant and const_idx\n",
    "        self._handle_constant(hasconst)\n",
    "        self._check_integrity()\n",
    "        self._cache = resettable_cache()\n",
    "\n",
    "    def _handle_constant(self, hasconst):\n",
    "        if hasconst is not None:\n",
    "            if hasconst:\n",
    "                self.k_constant = 1\n",
    "                self.const_idx = None\n",
    "            else:\n",
    "                self.k_constant = 0\n",
    "                self.const_idx = None\n",
    "        elif self.exog is None:\n",
    "            self.const_idx = None\n",
    "            self.k_constant = 0\n",
    "        else:\n",
    "            # detect where the constant is\n",
    "            check_implicit = False\n",
    "            const_idx = np.where(self.exog.ptp(axis=0) == 0)[0].squeeze()\n",
    "            self.k_constant = const_idx.size\n",
    "\n",
    "            if self.k_constant == 1:\n",
    "                if self.exog[:, const_idx].mean() != 0:\n",
    "                    self.const_idx = const_idx\n",
    "                else:\n",
    "                    # we only have a zero column and no other constant\n",
    "                    check_implicit = True\n",
    "            elif self.k_constant > 1:\n",
    "                # we have more than one constant column\n",
    "                # look for ones\n",
    "                values = []  # keep values if we need != 0\n",
    "                for idx in const_idx:\n",
    "                    value = self.exog[:, idx].mean()\n",
    "                    if value == 1:\n",
    "                        self.k_constant = 1\n",
    "                        self.const_idx = idx\n",
    "                        break\n",
    "                    values.append(value)\n",
    "                else:\n",
    "                    # we didn't break, no column of ones\n",
    "                    pos = (np.array(values) != 0)\n",
    "                    if pos.any():\n",
    "                        # take the first nonzero column\n",
    "                        self.k_constant = 1\n",
    "                        self.const_idx = const_idx[pos.argmax()]\n",
    "                    else:\n",
    "                        # only zero columns\n",
    "                        check_implicit = True\n",
    "            elif self.k_constant == 0:\n",
    "                check_implicit = True\n",
    "            else:\n",
    "                # shouldn't be here\n",
    "                pass\n",
    "\n",
    "            if check_implicit:\n",
    "                # look for implicit constant\n",
    "                # Compute rank of augmented matrix\n",
    "                augmented_exog = np.column_stack(\n",
    "                            (np.ones(self.exog.shape[0]), self.exog))\n",
    "                rank_augm = np_matrix_rank(augmented_exog)\n",
    "                rank_orig = np_matrix_rank(self.exog)\n",
    "                self.k_constant = int(rank_orig == rank_augm)\n",
    "                self.const_idx = None\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def _drop_nans(cls, x, nan_mask):\n",
    "        return x[nan_mask]\n",
    "\n",
    "    @classmethod\n",
    "    def _drop_nans_2d(cls, x, nan_mask):\n",
    "        return x[nan_mask][:, nan_mask]\n",
    "\n",
    "    @classmethod\n",
    "    def handle_missing(cls, endog, exog, missing, **kwargs):\n",
    "        \"\"\"\n",
    "        This returns a dictionary with keys endog, exog and the keys of\n",
    "        kwargs. It preserves Nones.\n",
    "        \"\"\"\n",
    "        none_array_names = []\n",
    "\n",
    "        # patsy's already dropped NaNs in y/X\n",
    "        missing_idx = kwargs.pop('missing_idx', None)\n",
    "\n",
    "        if missing_idx is not None:\n",
    "            # y, X already handled by patsy. add back in later.\n",
    "            combined = ()\n",
    "            combined_names = []\n",
    "            if exog is None:\n",
    "                none_array_names += ['exog']\n",
    "        elif exog is not None:\n",
    "            combined = (endog, exog)\n",
    "            combined_names = ['endog', 'exog']\n",
    "        else:\n",
    "            combined = (endog,)\n",
    "            combined_names = ['endog']\n",
    "            none_array_names += ['exog']\n",
    "\n",
    "        # deal with other arrays\n",
    "        combined_2d = ()\n",
    "        combined_2d_names = []\n",
    "        if len(kwargs):\n",
    "            for key, value_array in iteritems(kwargs):\n",
    "                if value_array is None or value_array.ndim == 0:\n",
    "                    none_array_names += [key]\n",
    "                    continue\n",
    "                # grab 1d arrays\n",
    "                if value_array.ndim == 1:\n",
    "                    combined += (np.asarray(value_array),)\n",
    "                    combined_names += [key]\n",
    "                elif value_array.squeeze().ndim == 1:\n",
    "                    combined += (np.asarray(value_array),)\n",
    "                    combined_names += [key]\n",
    "\n",
    "                # grab 2d arrays that are _assumed_ to be symmetric\n",
    "                elif value_array.ndim == 2:\n",
    "                    combined_2d += (np.asarray(value_array),)\n",
    "                    combined_2d_names += [key]\n",
    "                else:\n",
    "                    raise ValueError(\"Arrays with more than 2 dimensions \"\n",
    "                                     \"aren't yet handled\")\n",
    "\n",
    "        if missing_idx is not None:\n",
    "            nan_mask = missing_idx\n",
    "            updated_row_mask = None\n",
    "            if combined:  # there were extra arrays not handled by patsy\n",
    "                combined_nans = _nan_rows(*combined)\n",
    "                if combined_nans.shape[0] != nan_mask.shape[0]:\n",
    "                    raise ValueError(\"Shape mismatch between endog/exog \"\n",
    "                                     \"and extra arrays given to model.\")\n",
    "                # for going back and updated endog/exog\n",
    "                updated_row_mask = combined_nans[~nan_mask]\n",
    "                nan_mask |= combined_nans  # for updating extra arrays only\n",
    "            if combined_2d:\n",
    "                combined_2d_nans = _nan_rows(combined_2d)\n",
    "                if combined_2d_nans.shape[0] != nan_mask.shape[0]:\n",
    "                    raise ValueError(\"Shape mismatch between endog/exog \"\n",
    "                                     \"and extra 2d arrays given to model.\")\n",
    "                if updated_row_mask is not None:\n",
    "                    updated_row_mask |= combined_2d_nans[~nan_mask]\n",
    "                else:\n",
    "                    updated_row_mask = combined_2d_nans[~nan_mask]\n",
    "                nan_mask |= combined_2d_nans\n",
    "\n",
    "        else:\n",
    "            nan_mask = _nan_rows(*combined)\n",
    "            if combined_2d:\n",
    "                nan_mask = _nan_rows(*(nan_mask[:, None],) + combined_2d)\n",
    "\n",
    "        if not np.any(nan_mask):  # no missing don't do anything\n",
    "            combined = dict(zip(combined_names, combined))\n",
    "            if combined_2d:\n",
    "                combined.update(dict(zip(combined_2d_names, combined_2d)))\n",
    "            if none_array_names:\n",
    "                combined.update(dict(zip(none_array_names,\n",
    "                                         [None] * len(none_array_names))))\n",
    "\n",
    "            if missing_idx is not None:\n",
    "                combined.update({'endog': endog})\n",
    "                if exog is not None:\n",
    "                    combined.update({'exog': exog})\n",
    "\n",
    "            return combined, []\n",
    "\n",
    "        elif missing == 'raise':\n",
    "            raise MissingDataError(\"NaNs were encountered in the data\")\n",
    "\n",
    "        elif missing == 'drop':\n",
    "            nan_mask = ~nan_mask\n",
    "            drop_nans = lambda x: cls._drop_nans(x, nan_mask)\n",
    "            drop_nans_2d = lambda x: cls._drop_nans_2d(x, nan_mask)\n",
    "            combined = dict(zip(combined_names, lmap(drop_nans, combined)))\n",
    "\n",
    "            if missing_idx is not None:\n",
    "                if updated_row_mask is not None:\n",
    "                    updated_row_mask = ~updated_row_mask\n",
    "                    # update endog/exog with this new information\n",
    "                    endog = cls._drop_nans(endog, updated_row_mask)\n",
    "                    if exog is not None:\n",
    "                        exog = cls._drop_nans(exog, updated_row_mask)\n",
    "\n",
    "                combined.update({'endog': endog})\n",
    "                if exog is not None:\n",
    "                    combined.update({'exog': exog})\n",
    "\n",
    "            if combined_2d:\n",
    "                combined.update(dict(zip(combined_2d_names,\n",
    "                                         lmap(drop_nans_2d, combined_2d))))\n",
    "            if none_array_names:\n",
    "                combined.update(dict(zip(none_array_names,\n",
    "                                         [None] * len(none_array_names))))\n",
    "\n",
    "            return combined, np.where(~nan_mask)[0].tolist()\n",
    "        else:\n",
    "            raise ValueError(\"missing option %s not understood\" % missing)\n",
    "\n",
    "    def _convert_endog_exog(self, endog, exog):\n",
    "\n",
    "        # for consistent outputs if endog is (n,1)\n",
    "        yarr = self._get_yarr(endog)\n",
    "        xarr = None\n",
    "        if exog is not None:\n",
    "            xarr = self._get_xarr(exog)\n",
    "            if xarr.ndim == 1:\n",
    "                xarr = xarr[:, None]\n",
    "            if xarr.ndim != 2:\n",
    "                raise ValueError(\"exog is not 1d or 2d\")\n",
    "\n",
    "        return yarr, xarr\n",
    "\n",
    "    @cache_writable()\n",
    "    def ynames(self):\n",
    "        endog = self.orig_endog\n",
    "        ynames = self._get_names(endog)\n",
    "        if not ynames:\n",
    "            ynames = _make_endog_names(self.endog)\n",
    "\n",
    "        if len(ynames) == 1:\n",
    "            return ynames[0]\n",
    "        else:\n",
    "            return list(ynames)\n",
    "\n",
    "    @cache_writable()\n",
    "    def xnames(self):\n",
    "        exog = self.orig_exog\n",
    "        if exog is not None:\n",
    "            xnames = self._get_names(exog)\n",
    "            if not xnames:\n",
    "                xnames = _make_exog_names(self.exog)\n",
    "            return list(xnames)\n",
    "        return None\n",
    "\n",
    "    @property\n",
    "    def param_names(self):\n",
    "        # for handling names of 'extra' parameters in summary, etc.\n",
    "        return self._param_names or self.xnames\n",
    "\n",
    "    @param_names.setter\n",
    "    def param_names(self, values):\n",
    "        self._param_names = values\n",
    "\n",
    "    @cache_readonly\n",
    "    def row_labels(self):\n",
    "        exog = self.orig_exog\n",
    "        if exog is not None:\n",
    "            row_labels = self._get_row_labels(exog)\n",
    "        else:\n",
    "            endog = self.orig_endog\n",
    "            row_labels = self._get_row_labels(endog)\n",
    "        return row_labels\n",
    "\n",
    "    def _get_row_labels(self, arr):\n",
    "        return None\n",
    "\n",
    "    def _get_names(self, arr):\n",
    "        if isinstance(arr, DataFrame):\n",
    "            return list(arr.columns)\n",
    "        elif isinstance(arr, Series):\n",
    "            if arr.name:\n",
    "                return [arr.name]\n",
    "            else:\n",
    "                return\n",
    "        else:\n",
    "            try:\n",
    "                return arr.dtype.names\n",
    "            except AttributeError:\n",
    "                pass\n",
    "\n",
    "        return None\n",
    "\n",
    "    def _get_yarr(self, endog):\n",
    "        if data_util._is_structured_ndarray(endog):\n",
    "            endog = data_util.struct_to_ndarray(endog)\n",
    "        endog = np.asarray(endog)\n",
    "        if len(endog) == 1:  # never squeeze to a scalar\n",
    "            if endog.ndim == 1:\n",
    "                return endog\n",
    "            elif endog.ndim > 1:\n",
    "                return np.asarray([endog.squeeze()])\n",
    "\n",
    "        return endog.squeeze()\n",
    "\n",
    "    def _get_xarr(self, exog):\n",
    "        if data_util._is_structured_ndarray(exog):\n",
    "            exog = data_util.struct_to_ndarray(exog)\n",
    "        return np.asarray(exog)\n",
    "\n",
    "    def _check_integrity(self):\n",
    "        if self.exog is not None:\n",
    "            if len(self.exog) != len(self.endog):\n",
    "                raise ValueError(\"endog and exog matrices are different sizes\")\n",
    "\n",
    "    def wrap_output(self, obj, how='columns', names=None):\n",
    "        if how == 'columns':\n",
    "            return self.attach_columns(obj)\n",
    "        elif how == 'rows':\n",
    "            return self.attach_rows(obj)\n",
    "        elif how == 'cov':\n",
    "            return self.attach_cov(obj)\n",
    "        elif how == 'dates':\n",
    "            return self.attach_dates(obj)\n",
    "        elif how == 'columns_eq':\n",
    "            return self.attach_columns_eq(obj)\n",
    "        elif how == 'cov_eq':\n",
    "            return self.attach_cov_eq(obj)\n",
    "        elif how == 'generic_columns':\n",
    "            return self.attach_generic_columns(obj, names)\n",
    "        elif how == 'generic_columns_2d':\n",
    "            return self.attach_generic_columns_2d(obj, names)\n",
    "        else:\n",
    "            return obj\n",
    "\n",
    "    def attach_columns(self, result):\n",
    "        return result\n",
    "\n",
    "    def attach_columns_eq(self, result):\n",
    "        return result\n",
    "\n",
    "    def attach_cov(self, result):\n",
    "        return result\n",
    "\n",
    "    def attach_cov_eq(self, result):\n",
    "        return result\n",
    "\n",
    "    def attach_rows(self, result):\n",
    "        return result\n",
    "\n",
    "    def attach_dates(self, result):\n",
    "        return result\n",
    "\n",
    "    def attach_generic_columns(self, result, *args, **kwargs):\n",
    "        return result\n",
    "\n",
    "    def attach_generic_columns_2d(self, result, *args, **kwargs):\n",
    "        return result\n",
    "\n",
    "\n",
    "class PatsyData(ModelData):\n",
    "    def _get_names(self, arr):\n",
    "        return arr.design_info.column_names\n",
    "\n",
    "\n",
    "class PandasData(ModelData):\n",
    "    \"\"\"\n",
    "    Data handling class which knows how to reattach pandas metadata to model\n",
    "    results\n",
    "    \"\"\"\n",
    "\n",
    "    def _convert_endog_exog(self, endog, exog=None):\n",
    "        #TODO: remove this when we handle dtype systematically\n",
    "        endog = np.asarray(endog)\n",
    "        exog = exog if exog is None else np.asarray(exog)\n",
    "        if endog.dtype == object or exog is not None and exog.dtype == object:\n",
    "            raise ValueError(\"Pandas data cast to numpy dtype of object. \"\n",
    "                             \"Check input data with np.asarray(data).\")\n",
    "        return super(PandasData, self)._convert_endog_exog(endog, exog)\n",
    "\n",
    "    @classmethod\n",
    "    def _drop_nans(cls, x, nan_mask):\n",
    "        if hasattr(x, 'ix'):\n",
    "            return x.ix[nan_mask]\n",
    "        else:  # extra arguments could be plain ndarrays\n",
    "            return super(PandasData, cls)._drop_nans(x, nan_mask)\n",
    "\n",
    "    @classmethod\n",
    "    def _drop_nans_2d(cls, x, nan_mask):\n",
    "        if hasattr(x, 'ix'):\n",
    "            return x.ix[nan_mask].ix[:, nan_mask]\n",
    "        else:  # extra arguments could be plain ndarrays\n",
    "            return super(PandasData, cls)._drop_nans_2d(x, nan_mask)\n",
    "\n",
    "    def _check_integrity(self):\n",
    "        endog, exog = self.orig_endog, self.orig_exog\n",
    "        # exog can be None and we could be upcasting one or the other\n",
    "        if (exog is not None and\n",
    "                (hasattr(endog, 'index') and hasattr(exog, 'index')) and\n",
    "                not self.orig_endog.index.equals(self.orig_exog.index)):\n",
    "            raise ValueError(\"The indices for endog and exog are not aligned\")\n",
    "        super(PandasData, self)._check_integrity()\n",
    "\n",
    "    def _get_row_labels(self, arr):\n",
    "        try:\n",
    "            return arr.index\n",
    "        except AttributeError:\n",
    "            # if we've gotten here it's because endog is pandas and\n",
    "            # exog is not, so just return the row labels from endog\n",
    "            return self.orig_endog.index\n",
    "\n",
    "    def attach_generic_columns(self, result, names):\n",
    "        # get the attribute to use\n",
    "        column_names = getattr(self, names, None)\n",
    "        return Series(result, index=column_names)\n",
    "\n",
    "    def attach_generic_columns_2d(self, result, rownames, colnames=None):\n",
    "        colnames = colnames or rownames\n",
    "        rownames = getattr(self, rownames, None)\n",
    "        colnames = getattr(self, colnames, None)\n",
    "        return DataFrame(result, index=rownames, columns=colnames)\n",
    "\n",
    "    def attach_columns(self, result):\n",
    "        # this can either be a 1d array or a scalar\n",
    "        # don't squeeze because it might be a 2d row array\n",
    "        # if it needs a squeeze, the bug is elsewhere\n",
    "        if result.ndim <= 1:\n",
    "            return Series(result, index=self.param_names)\n",
    "        else:  # for e.g., confidence intervals\n",
    "            return DataFrame(result, index=self.param_names)\n",
    "\n",
    "    def attach_columns_eq(self, result):\n",
    "        return DataFrame(result, index=self.xnames, columns=self.ynames)\n",
    "\n",
    "    def attach_cov(self, result):\n",
    "        return DataFrame(result, index=self.param_names,\n",
    "                         columns=self.param_names)\n",
    "\n",
    "    def attach_cov_eq(self, result):\n",
    "        return DataFrame(result, index=self.ynames, columns=self.ynames)\n",
    "\n",
    "    def attach_rows(self, result):\n",
    "        # assumes if len(row_labels) > len(result) it's bc it was truncated\n",
    "        # at the front, for AR lags, for example\n",
    "        if result.squeeze().ndim == 1:\n",
    "            return Series(result, index=self.row_labels[-len(result):])\n",
    "        else:  # this is for VAR results, may not be general enough\n",
    "            return DataFrame(result, index=self.row_labels[-len(result):],\n",
    "                             columns=self.ynames)\n",
    "\n",
    "    def attach_dates(self, result):\n",
    "        return TimeSeries(result, index=self.predict_dates)\n",
    "\n",
    "\n",
    "def _make_endog_names(endog):\n",
    "    if endog.ndim == 1 or endog.shape[1] == 1:\n",
    "        ynames = ['y']\n",
    "    else:  # for VAR\n",
    "        ynames = ['y%d' % (i+1) for i in range(endog.shape[1])]\n",
    "\n",
    "    return ynames\n",
    "\n",
    "\n",
    "def _make_exog_names(exog):\n",
    "    exog_var = exog.var(0)\n",
    "    if (exog_var == 0).any():\n",
    "        # assumes one constant in first or last position\n",
    "        # avoid exception if more than one constant\n",
    "        const_idx = exog_var.argmin()\n",
    "        exog_names = ['x%d' % i for i in range(1, exog.shape[1])]\n",
    "        exog_names.insert(const_idx, 'const')\n",
    "    else:\n",
    "        exog_names = ['x%d' % i for i in range(1, exog.shape[1]+1)]\n",
    "\n",
    "    return exog_names\n",
    "\n",
    "\n",
    "def handle_missing(endog, exog=None, missing='none', **kwargs):\n",
    "    klass = handle_data_class_factory(endog, exog)\n",
    "    if missing == 'none':\n",
    "        ret_dict = dict(endog=endog, exog=exog)\n",
    "        ret_dict.update(kwargs)\n",
    "        return ret_dict, None\n",
    "    return klass.handle_missing(endog, exog, missing=missing, **kwargs)\n",
    "\n",
    "\n",
    "def handle_data_class_factory(endog, exog):\n",
    "    \"\"\"\n",
    "    Given inputs\n",
    "    \"\"\"\n",
    "    if data_util._is_using_ndarray_type(endog, exog):\n",
    "        klass = ModelData\n",
    "    elif data_util._is_using_pandas(endog, exog):\n",
    "        klass = PandasData\n",
    "    elif data_util._is_using_patsy(endog, exog):\n",
    "        klass = PatsyData\n",
    "    # keep this check last\n",
    "    elif data_util._is_using_ndarray(endog, exog):\n",
    "        klass = ModelData\n",
    "    else:\n",
    "        raise ValueError('unrecognized data structures: %s / %s' %\n",
    "                         (type(endog), type(exog)))\n",
    "    return klass\n",
    "\n",
    "\n",
    "def handle_data(endog, exog, missing='none', hasconst=None, **kwargs):\n",
    "    # deal with lists and tuples up-front\n",
    "    if isinstance(endog, (list, tuple)):\n",
    "        endog = np.asarray(endog)\n",
    "    if isinstance(exog, (list, tuple)):\n",
    "        exog = np.asarray(exog)\n",
    "\n",
    "    klass = handle_data_class_factory(endog, exog)\n",
    "    return klass(endog, exog=exog, missing=missing, hasconst=hasconst,\n",
    "                 **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'TimeSeries'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-fdec76f00533>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpylab\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpylab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstyle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marima_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mARIMA\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraphics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsaplots\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_acf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_pacf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\arima_model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m from statsmodels.tools.decorators import (cache_readonly,\n\u001b[0;32m     21\u001b[0m                                           resettable_cache)\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsa_model\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtsbase\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapper\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregression\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0myule_walker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGLS\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapper\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetools\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhandle_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrecipr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnan_dot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrast\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mContrastResults\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnp_matrix_rank\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTimeSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m from statsmodels.tools.decorators import (resettable_cache, cache_readonly,\n\u001b[0;32m     10\u001b[0m                                           cache_writable)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'TimeSeries'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas_datareader\n",
    "import datetime\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pylab import style\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
